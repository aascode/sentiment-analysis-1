{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment analysis preprocessing multiclass.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TukimOu3IeLK",
        "colab_type": "text"
      },
      "source": [
        "## some documentation\n",
        "- process slang:\n",
        "    * https://github.com/vi3k6i5/flashtext1\n",
        "    * https://github.com/cjhutto/vaderSentiment\n",
        "    * https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_Wliixqgmo2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "839219c3-da82-400e-d672-59ea192b178b"
      },
      "source": [
        "!pip install nltk \n",
        "!pip install stanza\n",
        "!pip install spacy\n",
        "!spacy download en_core_web_sm # sm md lg\n",
        "!python -m spacy download en"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: stanza in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.12.4)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (49.6.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.6.20)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (49.6.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.7.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (49.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (49.6.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixlc1Gg2gV6W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "5562f283-fbf4-4569-d933-4199122cfb82"
      },
      "source": [
        "# nltk\n",
        "import nltk\n",
        "from nltk.corpus import words\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('words')\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "NLTK_WORDS = set(words.words())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw0tfN636u4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nltk_lemma(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatizer.lemmatize(text)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBsjg0d5gde0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "5b3b5164-ebef-41d7-f816-1f892cf8214e"
      },
      "source": [
        "# Stanza NLP\n",
        "import stanza\n",
        "\n",
        "stanza.download('en', package='ewt', processors='tokenize,mwt,pos,lemma', verbose=True)\n",
        "stNLP = stanza.Pipeline(processors='tokenize,mwt,pos,lemma',\n",
        "                      lang='en',\n",
        "                      use_gpu=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 12.8MB/s]                    \n",
            "2020-08-26 22:43:58 WARNING: Can not find mwt: ewt from official model list. Ignoring it.\n",
            "2020-08-26 22:43:58 INFO: Downloading these customized packages for language: en (English)...\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ewt     |\n",
            "| pos       | ewt     |\n",
            "| lemma     | ewt     |\n",
            "| pretrain  | ewt     |\n",
            "=======================\n",
            "\n",
            "2020-08-26 22:43:58 INFO: File exists: /root/stanza_resources/en/tokenize/ewt.pt.\n",
            "2020-08-26 22:43:58 INFO: File exists: /root/stanza_resources/en/pos/ewt.pt.\n",
            "2020-08-26 22:43:58 INFO: File exists: /root/stanza_resources/en/lemma/ewt.pt.\n",
            "2020-08-26 22:43:59 INFO: File exists: /root/stanza_resources/en/pretrain/ewt.pt.\n",
            "2020-08-26 22:43:59 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2020-08-26 22:43:59 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
            "2020-08-26 22:43:59 INFO: Loading these models for language: en (English):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ewt     |\n",
            "| pos       | ewt     |\n",
            "| lemma     | ewt     |\n",
            "=======================\n",
            "\n",
            "2020-08-26 22:43:59 INFO: Use device: gpu\n",
            "2020-08-26 22:43:59 INFO: Loading: tokenize\n",
            "2020-08-26 22:44:02 INFO: Loading: pos\n",
            "2020-08-26 22:44:03 INFO: Loading: lemma\n",
            "2020-08-26 22:44:03 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjVJN1YM610R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# stanza\n",
        "def stanza_lemma(text):\n",
        "    doc = stNLP(text)\n",
        "    return ' '.join([word.lemma for sent in doc.sentences for word in sent.words])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-w_t_p3ghAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Spacy NLP\n",
        "import spacy\n",
        "spNLP = spacy.load('en_core_web_sm')\n",
        "spNLP.max_length = 103950039 # or higher\n",
        "# spacy.prefer_gpu() #will not work with stanza"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsdmGD0W4hLz",
        "colab_type": "text"
      },
      "source": [
        "### **VADER**\n",
        "* VADER, has different ratings depending on the form of the word and therefore the input should not be stemmed or lemmatized.\n",
        "\n",
        "* disadvantage of this approach is that Out of Vocab (OOV) words that the sentiment analysis tool has not seen before will not be classified as positive/negative (e.g. typos)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mco5OBKs4chP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "12fd9975-4a6f-460f-9ecb-8d3411aa1917"
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "SIA = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQCYZuxx5M9p",
        "colab_type": "text"
      },
      "source": [
        "### **TextBlob**\n",
        "* use a bag of words classifier, but the advantage is that it includes subjetivity analysis (factual/opinated)\n",
        "* it doesn't contain the heuristics that nltk has, it won't intensify or negate a sentence's sentiment\n",
        "\n",
        "* will return the subjectivity of the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIwXAmUq49o4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from textblob import TextBlob"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRd5wuv37TqR",
        "colab_type": "text"
      },
      "source": [
        "### **Flair**\n",
        "* classifier based on a character-leval LSTM. Takes a sequences of letters and words into account when predicting\n",
        "\n",
        "* one of its biggest advantages is that it can predict a sentiment for OOV words that it has never seen before too (such as typos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFf7QrkW5a1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82c09f7c-d5e6-4772-a00d-c33531bc9cfa"
      },
      "source": [
        "!pip3 install flair\n",
        "# tiene en cuenta secuencias de letras y palabras al predecir\n",
        "import flair\n",
        "flair_sent = flair.models.TextClassifier.load('en-sentiment')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flair in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.41.1)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair) (1.2.10)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.91)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.7)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.6.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.6.0+cu101)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3.2)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (from flair) (5.8)\n",
            "Requirement already satisfied: pytest>=5.3.2 in /usr/local/lib/python3.6/dist-packages (from flair) (6.0.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (from flair) (1.0.8)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair) (1.5.10)\n",
            "Requirement already satisfied: konoha[janome]<5.0.0,>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.6.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.11.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (0.16.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.3.2->flair) (2.23.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.9.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.7.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (20.1.0)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.13.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.0.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (20.4)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (8.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (0.8.1rc1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (0.7)\n",
            "Requirement already satisfied: overrides==3.0.0 in /usr/local/lib/python3.6/dist-packages (from konoha[janome]<5.0.0,>=4.0.0->flair) (3.0.0)\n",
            "Requirement already satisfied: janome<0.4.0,>=0.3.10; extra == \"janome\" or extra == \"all\" or extra == \"all_with_integrations\" in /usr/local/lib/python3.6/dist-packages (from konoha[janome]<5.0.0,>=4.0.0->flair) (0.3.10)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (1.14.47)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair) (3.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.0->flair) (7.1.2)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.47 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair) (1.17.47)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.4.0->flair) (0.10.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.47->boto3->smart-open>=1.2.1->gensim>=3.4.0->flair) (0.15.2)\n",
            "2020-08-26 23:03:28,035 loading file /root/.flair/models/sentiment-en-mix-distillbert.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRNVEmMM6q6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flair_lstm(text):\n",
        "    x = flair.data.Sentence(text)\n",
        "    flair_sent.predict(sentences=x)\n",
        "    total_sent = x.labels\n",
        "    return total_sent "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPT42-uxjgi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# labels\n",
        "highlights = {\n",
        "    # related with speech recognition\n",
        "    'professional qualities': ['handles pressure'],\n",
        "    'soft skills': ['silence'],\n",
        "    'answer analysis': ['filler words', 'long pause', 'focus', 'patience'], \n",
        "\n",
        "    'polarities': {\n",
        "        'negative': [\n",
        "                     # confidence\n",
        "                     'not confident', \n",
        "                     'unsure',\n",
        "\n",
        "                     # professional qualities\n",
        "                     '',\n",
        "                     'disordered',\n",
        "                     'talkative',\n",
        "                     'uninsterested', # 'engaged'\n",
        "\n",
        "                     # soft skills\n",
        "                     'sad',\n",
        "                     'unfriendly'\n",
        "                     ],\n",
        "\n",
        "        'positive': [\n",
        "                     # confidence\n",
        "                     'confident', \n",
        "                     'certany',\n",
        "\n",
        "                     # professional qualities\n",
        "                     'handles pressure',\n",
        "                     'organized',\n",
        "                     'concise', \n",
        "                     'interested', # 'engaged'\n",
        "\n",
        "                     # soft skills\n",
        "                     'happy',\n",
        "                     'friendly'\n",
        "                     ]\n",
        "    }\n",
        "}\n",
        "\n",
        "main_lst = list(highlights.values())\n",
        "main_labels = [k for j in main_lst for k in j]\n",
        "\n",
        "neg_pos_lst = highlights['polarities'].values()\n",
        "neg_pos_labels = [k for j in neg_pos_lst for k in j]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu_kEM5rqw-R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "17ec509a-77a9-4404-9433-bdc41c42bb55"
      },
      "source": [
        "neg_pos_lst"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([['not confident', 'unsure', '', 'disordered', 'talkative', 'uninsterested', 'sad', 'unfriendly'], ['confident', 'certany', 'handles pressure', 'organized', 'concise', 'interested', 'happy', 'friendly']])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW-j-i65kM9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "11e53b91-cc5f-4bc4-e25c-dd220827d14b"
      },
      "source": [
        "neg_pos_labels"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['not confident',\n",
              " 'unsure',\n",
              " '',\n",
              " 'disordered',\n",
              " 'talkative',\n",
              " 'uninsterested',\n",
              " 'sad',\n",
              " 'unfriendly',\n",
              " 'confident',\n",
              " 'certany',\n",
              " 'handles pressure',\n",
              " 'organized',\n",
              " 'concise',\n",
              " 'interested',\n",
              " 'happy',\n",
              " 'friendly']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiUnT6TnrUgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import re"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FbDdGQcwqPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(data_path=None):\n",
        "    print('load the dataset...\\n')\n",
        "    !mkdir -p data\n",
        "    !wget -nc https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/sentiment-analysis-is-bad/data/training.1600000.processed.noemoticon.csv.zip -P data\n",
        "    !unzip -n -d data data/training.1600000.processed.noemoticon.csv.zip"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I71x7SvXwmH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_dataset(PATH_FILE, index_col=None):\n",
        "    print('preprocess the dataset...\\n')\n",
        "\n",
        "    # load_data\n",
        "    load_data()\n",
        "    print('Database loaded\\n')\n",
        "\n",
        "    # cleaning data\n",
        "    unclean_df = pd.read_csv(PATH_FILE,\n",
        "                     names=['polarity', 'id', 'date', 'query', 'user', 'text'],\n",
        "                     encoding='latin-1') # if utf-8: UnicodeDecodeError: 'utf-8' codec can't decode bytes in position 232719-232720: invalid continuation byte\n",
        "\n",
        "    # replace polarity\n",
        "    unclean_df.polarity = unclean_df.polarity.replace({0: 0, 4: 1}) \n",
        "    \n",
        "    # dropping unneeded columns\n",
        "    unclean_df = unclean_df.drop(columns=['id', 'date', 'query', 'user']) \n",
        "\n",
        "    # lower case\n",
        "    unclean_df['text'] = unclean_df['text'].str.lower()\n",
        "\n",
        "    # removing urls\n",
        "    unclean_df['text'] = unclean_df['text'].apply(lambda x: re.sub(r'https://www\\.|http:\\.|https://|www\\.', '', x))\n",
        "    unclean_df['text'] = unclean_df['text'].apply(lambda x: re.sub(r'[\\S]+\\.(net|com|org|info|edu|gov|uk|de|ca|jp|fr|au|us|ru|ch|it|nel|se|no|es|mil|cl)[\\S]*\\s?', '', x))\n",
        "\n",
        "    # remove special character and numbers\n",
        "    #unclean_df['text'] = unclean_df['text'].apply(lambda x: re.sub(r'(@[A-Za-z0-9]+)|([^0-9A-Za-zÁ-Úá-ú \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?%', '', x))\n",
        "    #unclean_df['text'] = unclean_df['text'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
        "\n",
        "    # remove repetitions (goood ==> god)\n",
        "    pattern = re.compile(r'(.)\\1{2,}', re.DOTALL)\n",
        "    unclean_df['text'] = unclean_df['text'].str.replace(pattern, r'\\1')\n",
        "\n",
        "    # removing empty values replacing them with nan\n",
        "    nan_value = float('NaN')\n",
        "    unclean_df.replace('', nan_value, inplace=True)\n",
        "    unclean_df.dropna(inplace=True) # add subset\n",
        "\n",
        "    # removing stopwords\n",
        "    #df['text'] = df['text'].apply(lambda x: ' '.join([i for i in x.split() if i not in (STOPWORDS)]))\n",
        "\n",
        "    # filtering and removing non-english words or misspelling\n",
        "    #df['text'] = df['text'].apply(lambda x: ' '.join([i for i in x.split() if i.lower() in NLTK_WORDS or not i.isalpha()]))\n",
        "\n",
        "    # rewritting the created file without NaN values\n",
        "    unclean_df.to_csv('data/sentiment140-subset.csv', \n",
        "              quotechar='\"', # check later!\n",
        "              encoding='utf-8',\n",
        "              index=False)\n",
        "\n",
        "    # clean csv\n",
        "    df = pd.read_csv('data/sentiment140-subset.csv', encoding='utf-8', warn_bad_lines=True).dropna()\n",
        "\n",
        "    # checking if there's any NaN values\n",
        "    isnull = [i for i in (df['text'].isnull()) if i == True]\n",
        "    if isnull != []:\n",
        "        sys.exit(0) # add response object here\n",
        "\n",
        "    return df"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CinwlW5wxvxn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "4a2fe4b0-2d4e-4f02-efb8-10e5910bb370"
      },
      "source": [
        "df = preprocess_dataset(PATH_FILE='data/training.1600000.processed.noemoticon.csv')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocess the dataset...\n",
            "\n",
            "load the dataset...\n",
            "\n",
            "File ‘data/training.1600000.processed.noemoticon.csv.zip’ already there; not retrieving.\n",
            "\n",
            "Archive:  data/training.1600000.processed.noemoticon.csv.zip\n",
            "Database loaded\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27Z1KhXGCzGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "84b0be60-df10-44c5-9551-534a785cdc07"
      },
      "source": [
        "df.text[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"@switchfoot - aw, that's a bummer.  you shoulda got david carr of third day to do it. ;d\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8BnSDw8R_bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def siaVader_compound(data):\n",
        "    scores = SIA.polarity_scores(data)\n",
        "    \n",
        "    comp_score = scores['compound']\n",
        "    if comp_score >= 0.05:\n",
        "        str_comp = 'pos'\n",
        "    elif comp_score <= -0.05:\n",
        "        str_comp = 'neg'\n",
        "    else: # (compound score > -0.05) and (compound score < 0.05)\n",
        "        str_comp = 'neu'\n",
        "    return str_comp\n",
        "\n",
        "def siaVader_maxScore(data):\n",
        "    scores = SIA.polarity_scores(data)\n",
        "    \n",
        "    del scores['compound']\n",
        "    index = np.argmax(list(scores.values()))\n",
        "    vader_MaxScore = list(scores.values())[index]\n",
        "    vader_label = list(scores)[index]\n",
        "    \n",
        "    return vader_label\n",
        "\n",
        "def siaVader_byWord(text):\n",
        "    c = 0\n",
        "    for n, y in enumerate(text):\n",
        "        x = SIA.polarity_scores(y)\n",
        "        if x['compound'] != 0.0:\n",
        "            c += 1\n",
        "            # print('{}. {} {}'.format(c, x, y))\n",
        "            return 'pos' if x > 0.05 else 'neg'"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8lMisAgMR0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['comp_label'] = df['text'].apply(lambda x: siaVader_compound(data=x))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13FO26_dgplF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['maxScore_label'] = df['text'].apply(lambda x: siaVader_maxScore(data=x))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXT4vF2ry7w_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['comp_score'] = df['text'].apply(lambda x: SIA.polarity_scores(x)['compound'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnVDjtKzYJv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['SIA'] = df['text'].apply(lambda x: SIA.polarity_scores(x))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed4C-h7I4oQJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "2e894023-9869-4eeb-a1fe-04d98ee9c302"
      },
      "source": [
        "df.tail(30)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>text</th>\n",
              "      <th>comp_label</th>\n",
              "      <th>maxScore_label</th>\n",
              "      <th>comp_score</th>\n",
              "      <th>SIA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1599921</th>\n",
              "      <td>1</td>\n",
              "      <td>thanks  amp  thanks that was just what i was l...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.7003</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599922</th>\n",
              "      <td>1</td>\n",
              "      <td>thanks martin not the most imaginative interf...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.2382</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.849, 'pos': 0.151, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599923</th>\n",
              "      <td>1</td>\n",
              "      <td>congrats mike  way to go</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.5267</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.541, 'pos': 0.459, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599924</th>\n",
              "      <td>1</td>\n",
              "      <td>omg office space i wanna steal it</td>\n",
              "      <td>neg</td>\n",
              "      <td>neu</td>\n",
              "      <td>-0.4939</td>\n",
              "      <td>{'neg': 0.39, 'neu': 0.61, 'pos': 0.0, 'compou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599925</th>\n",
              "      <td>1</td>\n",
              "      <td>ahaha nooo you were just away from everyone e...</td>\n",
              "      <td>neg</td>\n",
              "      <td>neu</td>\n",
              "      <td>-0.7717</td>\n",
              "      <td>{'neg': 0.242, 'neu': 0.758, 'pos': 0.0, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599926</th>\n",
              "      <td>1</td>\n",
              "      <td>hey im baack and thanks so much for all thos...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.8316</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.705, 'pos': 0.295, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599927</th>\n",
              "      <td>1</td>\n",
              "      <td>yeah my conscience would be clear in that case</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.5859</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.593, 'pos': 0.407, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599928</th>\n",
              "      <td>1</td>\n",
              "      <td>thats my girl  dishing out the quotadvicequot</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599929</th>\n",
              "      <td>1</td>\n",
              "      <td>i second that</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599930</th>\n",
              "      <td>1</td>\n",
              "      <td>in the garden</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599931</th>\n",
              "      <td>1</td>\n",
              "      <td>jo jen by nemuselo zrovna tã holce ael co nic</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599932</th>\n",
              "      <td>1</td>\n",
              "      <td>another commenting contest  yay</td>\n",
              "      <td>pos</td>\n",
              "      <td>pos</td>\n",
              "      <td>0.5267</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.469, 'pos': 0.531, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599933</th>\n",
              "      <td>1</td>\n",
              "      <td>i figured out how to see my tweets and facebo...</td>\n",
              "      <td>neg</td>\n",
              "      <td>neu</td>\n",
              "      <td>-0.2023</td>\n",
              "      <td>{'neg': 0.128, 'neu': 0.775, 'pos': 0.097, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599934</th>\n",
              "      <td>1</td>\n",
              "      <td>theri tomorrow drinking coffee talking about ...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.2716</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.878, 'pos': 0.122, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599935</th>\n",
              "      <td>1</td>\n",
              "      <td>you heard it here first  were having a girl ho...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.5106</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.788, 'pos': 0.212, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599936</th>\n",
              "      <td>1</td>\n",
              "      <td>if ur the lead singer in a band beware falling...</td>\n",
              "      <td>neg</td>\n",
              "      <td>neu</td>\n",
              "      <td>-0.1531</td>\n",
              "      <td>{'neg': 0.091, 'neu': 0.909, 'pos': 0.0, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599937</th>\n",
              "      <td>1</td>\n",
              "      <td>too much ads on my blog</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599938</th>\n",
              "      <td>1</td>\n",
              "      <td>ra neveer  i think that you both will get on w...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.2732</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.851, 'pos': 0.149, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599939</th>\n",
              "      <td>1</td>\n",
              "      <td>everitt ha good job thats right  we gotta thro...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.6486</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.762, 'pos': 0.238, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599940</th>\n",
              "      <td>1</td>\n",
              "      <td>hiphop im glad ur doing well</td>\n",
              "      <td>pos</td>\n",
              "      <td>pos</td>\n",
              "      <td>0.6249</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.44, 'pos': 0.56, 'compou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599941</th>\n",
              "      <td>1</td>\n",
              "      <td>wooooo xbox is back</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599942</th>\n",
              "      <td>1</td>\n",
              "      <td>mmmm  that sounds absolutely perfect but my ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>neu</td>\n",
              "      <td>-0.2967</td>\n",
              "      <td>{'neg': 0.153, 'neu': 0.744, 'pos': 0.103, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599943</th>\n",
              "      <td>1</td>\n",
              "      <td>recovering from the long weekend</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599944</th>\n",
              "      <td>1</td>\n",
              "      <td>gritboys</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599945</th>\n",
              "      <td>1</td>\n",
              "      <td>forster yeah that does work better than just w...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.7906</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.724, 'pos': 0.276, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599946</th>\n",
              "      <td>1</td>\n",
              "      <td>just woke up having no school is the best feel...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.5423</td>\n",
              "      <td>{'neg': 0.138, 'neu': 0.503, 'pos': 0.358, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599947</th>\n",
              "      <td>1</td>\n",
              "      <td>very cool to hear old walt interviews  â</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.3804</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.698, 'pos': 0.302, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599948</th>\n",
              "      <td>1</td>\n",
              "      <td>are you ready for your mojo makeover ask me fo...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.8, 'pos': 0.2, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599949</th>\n",
              "      <td>1</td>\n",
              "      <td>happy th birthday to my boo of alll time tupac...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.5719</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.748, 'pos': 0.252, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599950</th>\n",
              "      <td>1</td>\n",
              "      <td>happy charitytuesday</td>\n",
              "      <td>pos</td>\n",
              "      <td>pos</td>\n",
              "      <td>0.5719</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.213, 'pos': 0.787, 'comp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         polarity  ...                                                SIA\n",
              "1599921         1  ...  {'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compou...\n",
              "1599922         1  ...  {'neg': 0.0, 'neu': 0.849, 'pos': 0.151, 'comp...\n",
              "1599923         1  ...  {'neg': 0.0, 'neu': 0.541, 'pos': 0.459, 'comp...\n",
              "1599924         1  ...  {'neg': 0.39, 'neu': 0.61, 'pos': 0.0, 'compou...\n",
              "1599925         1  ...  {'neg': 0.242, 'neu': 0.758, 'pos': 0.0, 'comp...\n",
              "1599926         1  ...  {'neg': 0.0, 'neu': 0.705, 'pos': 0.295, 'comp...\n",
              "1599927         1  ...  {'neg': 0.0, 'neu': 0.593, 'pos': 0.407, 'comp...\n",
              "1599928         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599929         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599930         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599931         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599932         1  ...  {'neg': 0.0, 'neu': 0.469, 'pos': 0.531, 'comp...\n",
              "1599933         1  ...  {'neg': 0.128, 'neu': 0.775, 'pos': 0.097, 'co...\n",
              "1599934         1  ...  {'neg': 0.0, 'neu': 0.878, 'pos': 0.122, 'comp...\n",
              "1599935         1  ...  {'neg': 0.0, 'neu': 0.788, 'pos': 0.212, 'comp...\n",
              "1599936         1  ...  {'neg': 0.091, 'neu': 0.909, 'pos': 0.0, 'comp...\n",
              "1599937         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599938         1  ...  {'neg': 0.0, 'neu': 0.851, 'pos': 0.149, 'comp...\n",
              "1599939         1  ...  {'neg': 0.0, 'neu': 0.762, 'pos': 0.238, 'comp...\n",
              "1599940         1  ...  {'neg': 0.0, 'neu': 0.44, 'pos': 0.56, 'compou...\n",
              "1599941         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599942         1  ...  {'neg': 0.153, 'neu': 0.744, 'pos': 0.103, 'co...\n",
              "1599943         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599944         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599945         1  ...  {'neg': 0.0, 'neu': 0.724, 'pos': 0.276, 'comp...\n",
              "1599946         1  ...  {'neg': 0.138, 'neu': 0.503, 'pos': 0.358, 'co...\n",
              "1599947         1  ...  {'neg': 0.0, 'neu': 0.698, 'pos': 0.302, 'comp...\n",
              "1599948         1  ...  {'neg': 0.0, 'neu': 0.8, 'pos': 0.2, 'compound...\n",
              "1599949         1  ...  {'neg': 0.0, 'neu': 0.748, 'pos': 0.252, 'comp...\n",
              "1599950         1  ...  {'neg': 0.0, 'neu': 0.213, 'pos': 0.787, 'comp...\n",
              "\n",
              "[30 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}
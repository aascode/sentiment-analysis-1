{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment analysis preprocessing multiclass.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TukimOu3IeLK",
        "colab_type": "text"
      },
      "source": [
        "## some documentation\n",
        "- process slang:\n",
        "    * https://github.com/vi3k6i5/flashtext1\n",
        "    * https://github.com/cjhutto/vaderSentiment\n",
        "    * https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_Wliixqgmo2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e08f748f-f2ee-4cd8-9779-92bb7aa9915b"
      },
      "source": [
        "!pip install nltk \n",
        "!pip install stanza\n",
        "!pip install spacy\n",
        "!spacy download en_core_web_sm # sm md lg\n",
        "!python -m spacy download en"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: stanza in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.12.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.6.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.18.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (49.6.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.7.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (49.6.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (49.6.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (49.6.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixlc1Gg2gV6W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "b3c0da49-832d-41e2-b01a-afadba88c991"
      },
      "source": [
        "# nltk\n",
        "import nltk\n",
        "from nltk.corpus import words\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('words')\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "NLTK_WORDS = set(words.words())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBsjg0d5gde0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "3b43e787-5476-4049-f350-416cad8f2b72"
      },
      "source": [
        "# Stanza NLP\n",
        "import stanza\n",
        "\n",
        "stanza.download('en', package='ewt', processors='tokenize,mwt,pos,lemma', verbose=True)\n",
        "stNLP = stanza.Pipeline(processors='tokenize,mwt,pos,lemma',\n",
        "                      lang='en',\n",
        "                      use_gpu=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 20.6MB/s]                    \n",
            "2020-08-26 06:46:00 WARNING: Can not find mwt: ewt from official model list. Ignoring it.\n",
            "2020-08-26 06:46:00 INFO: Downloading these customized packages for language: en (English)...\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ewt     |\n",
            "| pos       | ewt     |\n",
            "| lemma     | ewt     |\n",
            "| pretrain  | ewt     |\n",
            "=======================\n",
            "\n",
            "2020-08-26 06:46:00 INFO: File exists: /root/stanza_resources/en/tokenize/ewt.pt.\n",
            "2020-08-26 06:46:00 INFO: File exists: /root/stanza_resources/en/pos/ewt.pt.\n",
            "2020-08-26 06:46:00 INFO: File exists: /root/stanza_resources/en/lemma/ewt.pt.\n",
            "2020-08-26 06:46:00 INFO: File exists: /root/stanza_resources/en/pretrain/ewt.pt.\n",
            "2020-08-26 06:46:00 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2020-08-26 06:46:00 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
            "2020-08-26 06:46:00 INFO: Loading these models for language: en (English):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ewt     |\n",
            "| pos       | ewt     |\n",
            "| lemma     | ewt     |\n",
            "=======================\n",
            "\n",
            "2020-08-26 06:46:00 INFO: Use device: gpu\n",
            "2020-08-26 06:46:00 INFO: Loading: tokenize\n",
            "2020-08-26 06:46:03 INFO: Loading: pos\n",
            "2020-08-26 06:46:04 INFO: Loading: lemma\n",
            "2020-08-26 06:46:04 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-w_t_p3ghAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Spacy NLP\n",
        "import spacy\n",
        "spNLP = spacy.load('en_core_web_sm')\n",
        "spNLP.max_length = 103950039 # or higher\n",
        "# spacy.prefer_gpu() #will not work with stanza"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qILtnyZegFuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nltk_lemma(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatizer.lemmatize(text)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfYnk5KhgDwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lemmatizion\n",
        "# stanza\n",
        "def stanza_lemma(text):\n",
        "    doc = stNLP(text)\n",
        "    return ' '.join([word.lemma for sent in doc.sentences for word in sent.words])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPT42-uxjgi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# labels\n",
        "highlights = {\n",
        "    # related with speech recognition\n",
        "    'professional qualities': ['handles pressure'],\n",
        "    'soft skills': ['silence'],\n",
        "    'answer analysis': ['filler words', 'long pause', 'focus', 'patience'], \n",
        "\n",
        "    'polarities': {\n",
        "        'negative': [\n",
        "                     # confidence\n",
        "                     'not confident', \n",
        "                     'unsure',\n",
        "\n",
        "                     # professional qualities\n",
        "                     '',\n",
        "                     'disordered',\n",
        "                     'talkative',\n",
        "                     'uninsterested', # 'engaged'\n",
        "\n",
        "                     # soft skills\n",
        "                     'sad',\n",
        "                     'unfriendly'\n",
        "                     ],\n",
        "\n",
        "        'positive': [\n",
        "                     # confidence\n",
        "                     'confident', \n",
        "                     'certany',\n",
        "\n",
        "                     # professional qualities\n",
        "                     'handles pressure',\n",
        "                     'organized',\n",
        "                     'concise', \n",
        "                     'interested', # 'engaged'\n",
        "\n",
        "                     # soft skills\n",
        "                     'happy',\n",
        "                     'friendly'\n",
        "                     ]\n",
        "    }\n",
        "}\n",
        "\n",
        "main_lst = list(highlights.values())\n",
        "main_labels = [k for j in main_lst for k in j]\n",
        "\n",
        "neg_pos_lst = highlights['polarities'].values()\n",
        "neg_pos_labels = [k for j in neg_pos_lst for k in j]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu_kEM5rqw-R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b4fd2884-86b7-4abe-f849-59abd4e392fc"
      },
      "source": [
        "neg_pos_lst"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_values([['not confident', 'unsure', '', 'disordered', 'talkative', 'uninsterested', 'sad', 'unfriendly'], ['confident', 'certany', 'handles pressure', 'organized', 'concise', 'interested', 'happy', 'friendly']])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW-j-i65kM9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "816cad4c-c2b8-4ad4-e6e7-b390c6fdfd6d"
      },
      "source": [
        "neg_pos_labels"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['not confident',\n",
              " 'unsure',\n",
              " '',\n",
              " 'disordered',\n",
              " 'talkative',\n",
              " 'uninsterested',\n",
              " 'sad',\n",
              " 'unfriendly',\n",
              " 'confident',\n",
              " 'certany',\n",
              " 'handles pressure',\n",
              " 'organized',\n",
              " 'concise',\n",
              " 'interested',\n",
              " 'happy',\n",
              " 'friendly']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiUnT6TnrUgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import re"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FbDdGQcwqPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(data_path=None):\n",
        "    print('load the dataset...\\n')\n",
        "    !mkdir -p data\n",
        "    !wget -nc https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/sentiment-analysis-is-bad/data/training.1600000.processed.noemoticon.csv.zip -P data\n",
        "    !unzip -n -d data data/training.1600000.processed.noemoticon.csv.zip"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I71x7SvXwmH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_dataset(PATH_FILE, index_col=None):\n",
        "    print('preprocess the dataset...\\n')\n",
        "\n",
        "    # load_data\n",
        "    load_data()\n",
        "    print('Database loaded\\n')\n",
        "\n",
        "    # cleaning data\n",
        "    unclean_df = pd.read_csv(PATH_FILE,\n",
        "                     names=['polarity', 'id', 'date', 'query', 'user', 'text'],\n",
        "                     encoding='latin-1') # if utf-8: UnicodeDecodeError: 'utf-8' codec can't decode bytes in position 232719-232720: invalid continuation byte\n",
        "\n",
        "    unclean_df.polarity = unclean_df.polarity.replace({0: 0, 4: 1}) # replace polarity\n",
        "    unclean_df = unclean_df.drop(columns=['id', 'date', 'query', 'user']) # dropping unneeded columns\n",
        "\n",
        "    # sample\n",
        "    #df_sample = unclean_df.sample(n=500000)\n",
        "    #df_sample.polarity.value_counts()\n",
        "\n",
        "    # lower case\n",
        "    unclean_df['text'] = unclean_df['text'].str.lower()\n",
        "\n",
        "    # remove character and numbers\n",
        "    unclean_df['text'] = unclean_df['text'].apply(lambda x: re.sub(r'https://www\\.|http:\\.|https://|www\\.', '', x))\n",
        "    unclean_df['text'] = unclean_df['text'].apply(lambda x: re.sub(r'[\\S]+\\.(net|com|org|info|edu|gov|uk|de|ca|jp|fr|au|us|ru|ch|it|nel|se|no|es|mil|cl)[\\S]*\\s?', '', x))\n",
        "    unclean_df['text'] = unclean_df['text'].apply(lambda x: re.sub(r'(@[A-Za-z0-9]+)|([^0-9A-Za-zÁ-Úá-ú \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?%', '', x))\n",
        "    unclean_df['text'] = unclean_df['text'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
        "\n",
        "    # rewritting the created file without NaN values\n",
        "    unclean_df.to_csv('data/sentiment140-subset.csv', \n",
        "              quotechar='\"', # check later!\n",
        "              encoding='utf-8',\n",
        "              index=False)\n",
        "\n",
        "    # clean csv\n",
        "    df = pd.read_csv('data/sentiment140-subset.csv', encoding='utf-8', warn_bad_lines=True).dropna()\n",
        "\n",
        "    # checking if there's any NaN values\n",
        "    isnull = [i for i in (df['text'].isnull()) if i == True]\n",
        "    if isnull != []:\n",
        "        sys.exit(0) # add response object here\n",
        "\n",
        "    return df"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CinwlW5wxvxn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "5d310df9-a0bc-4663-e267-44c68411e7f8"
      },
      "source": [
        "df = preprocess_dataset(PATH_FILE='data/training.1600000.processed.noemoticon.csv')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocess the dataset...\n",
            "\n",
            "load the dataset...\n",
            "\n",
            "File ‘data/training.1600000.processed.noemoticon.csv.zip’ already there; not retrieving.\n",
            "\n",
            "Archive:  data/training.1600000.processed.noemoticon.csv.zip\n",
            "Database loaded\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-Ary8Ubf4IQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# removing empty values replacing them with nan\n",
        "nan_value = float('NaN')\n",
        "df.replace('', nan_value, inplace=True)\n",
        "df.dropna(inplace=True) # add subset"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o439kfNHsyJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# removing stopwords\n",
        "#df['text'] = df['text'].apply(lambda x: ' '.join([i for i in x.split() if i not in (STOPWORDS)]))\n",
        "\n",
        "# filtering and removing non-english words or misspelling\n",
        "#df['text'] = df['text'].apply(lambda x: ' '.join([i for i in x.split() if i.lower() in NLTK_WORDS or not i.isalpha()]))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvc4c6VlwO9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0b8b8740-d6f0-4bfc-d769-a19e8f467de6"
      },
      "source": [
        "# VADER, has different ratings depending on the form of the word and therefore the input should not be stemmed or lemmatized.\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "SIA = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8BnSDw8R_bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sia_vader(data, compound=False):\n",
        "    scores = SIA.polarity_scores(data)\n",
        "    \n",
        "    if compound:\n",
        "        comp_score = scores['compound']\n",
        "        if comp_score >= 0.05:\n",
        "            str_comp = 'pos'\n",
        "        elif comp_score <= -0.05:\n",
        "            str_comp = 'neg'\n",
        "        else: # (compound score > -0.05) and (compound score < 0.05)\n",
        "            str_comp = 'neu'\n",
        "        return str_comp\n",
        "    else:\n",
        "        del scores['compound']\n",
        "\n",
        "        index = np.argmax(list(scores.values()))\n",
        "        vader_MaxScore = list(scores.values())[index]\n",
        "        vader_label = list(scores)[index]\n",
        "\n",
        "        return vader_label"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8lMisAgMR0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['compound_score'] = df['text'].apply(lambda x: sia_vader(data=x, compound=True))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13FO26_dgplF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['vader'] = df['text'].apply(lambda x: sia_vader(x))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXT4vF2ry7w_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['score'] = df['text'].apply(lambda x: SIA.polarity_scores(x)['compound'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnVDjtKzYJv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['SIA'] = df['text'].apply(lambda x: SIA.polarity_scores(x))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGcngDd2iMoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41796cee-5507-46d2-a38f-70904a6fabbd"
      },
      "source": [
        "df.tail(40)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>text</th>\n",
              "      <th>compound_score</th>\n",
              "      <th>vader</th>\n",
              "      <th>score</th>\n",
              "      <th>SIA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1599960</th>\n",
              "      <td>1</td>\n",
              "      <td>love the donut and the toadstool</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.6369</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.543, 'pos': 0.457, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599961</th>\n",
              "      <td>1</td>\n",
              "      <td>skip the aquarium and check out these fish   ...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.4215</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.781, 'pos': 0.219, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599962</th>\n",
              "      <td>1</td>\n",
              "      <td>yeah im being an ass today</td>\n",
              "      <td>neg</td>\n",
              "      <td>neu</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>{'neg': 0.361, 'neu': 0.412, 'pos': 0.227, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599963</th>\n",
              "      <td>1</td>\n",
              "      <td>its sunoudy</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599964</th>\n",
              "      <td>1</td>\n",
              "      <td>newsflash it worked</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599965</th>\n",
              "      <td>1</td>\n",
              "      <td>hi thanks for the follow nice website check y...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.6908</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599966</th>\n",
              "      <td>1</td>\n",
              "      <td>got home an hour ago ate lunch watched some tv...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.2960</td>\n",
              "      <td>{'neg': 0.083, 'neu': 0.789, 'pos': 0.128, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599967</th>\n",
              "      <td>1</td>\n",
              "      <td>checking my mail</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599968</th>\n",
              "      <td>1</td>\n",
              "      <td>done la examen easy peasy  so proud of myself</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.7425</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.527, 'pos': 0.473, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599969</th>\n",
              "      <td>1</td>\n",
              "      <td>youre the undisputed authority on the topic  ...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0772</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.86, 'pos': 0.14, 'compou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599970</th>\n",
              "      <td>1</td>\n",
              "      <td>thanks  amp  thanks that was just what i was l...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.7003</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599971</th>\n",
              "      <td>1</td>\n",
              "      <td>thanks martin not the most imaginative interf...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.2382</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.849, 'pos': 0.151, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599972</th>\n",
              "      <td>1</td>\n",
              "      <td>congrats mike  way to go</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.5267</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.541, 'pos': 0.459, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599973</th>\n",
              "      <td>1</td>\n",
              "      <td>omg office space i wanna steal it</td>\n",
              "      <td>neg</td>\n",
              "      <td>neu</td>\n",
              "      <td>-0.4939</td>\n",
              "      <td>{'neg': 0.39, 'neu': 0.61, 'pos': 0.0, 'compou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599974</th>\n",
              "      <td>1</td>\n",
              "      <td>ahaha nooo you were just away from everyone e...</td>\n",
              "      <td>neg</td>\n",
              "      <td>neu</td>\n",
              "      <td>-0.7717</td>\n",
              "      <td>{'neg': 0.242, 'neu': 0.758, 'pos': 0.0, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599975</th>\n",
              "      <td>1</td>\n",
              "      <td>hey im baack and thanks so much for all thos...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.8316</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.705, 'pos': 0.295, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599976</th>\n",
              "      <td>1</td>\n",
              "      <td>yeah my conscience would be clear in that case</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.5859</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.593, 'pos': 0.407, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599977</th>\n",
              "      <td>1</td>\n",
              "      <td>thats my girl  dishing out the quotadvicequot</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599978</th>\n",
              "      <td>1</td>\n",
              "      <td>i second that</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599979</th>\n",
              "      <td>1</td>\n",
              "      <td>in the garden</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599980</th>\n",
              "      <td>1</td>\n",
              "      <td>jo jen by nemuselo zrovna tã holce ael co nic</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599981</th>\n",
              "      <td>1</td>\n",
              "      <td>another commenting contest  yay</td>\n",
              "      <td>pos</td>\n",
              "      <td>pos</td>\n",
              "      <td>0.5267</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.469, 'pos': 0.531, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599982</th>\n",
              "      <td>1</td>\n",
              "      <td>i figured out how to see my tweets and facebo...</td>\n",
              "      <td>neg</td>\n",
              "      <td>neu</td>\n",
              "      <td>-0.2023</td>\n",
              "      <td>{'neg': 0.128, 'neu': 0.775, 'pos': 0.097, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599983</th>\n",
              "      <td>1</td>\n",
              "      <td>theri tomorrow drinking coffee talking about ...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.2716</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.878, 'pos': 0.122, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599984</th>\n",
              "      <td>1</td>\n",
              "      <td>you heard it here first  were having a girl ho...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.5106</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.788, 'pos': 0.212, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599985</th>\n",
              "      <td>1</td>\n",
              "      <td>if ur the lead singer in a band beware falling...</td>\n",
              "      <td>neg</td>\n",
              "      <td>neu</td>\n",
              "      <td>-0.1531</td>\n",
              "      <td>{'neg': 0.091, 'neu': 0.909, 'pos': 0.0, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599986</th>\n",
              "      <td>1</td>\n",
              "      <td>too much ads on my blog</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599987</th>\n",
              "      <td>1</td>\n",
              "      <td>ra neveer  i think that you both will get on w...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.2732</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.851, 'pos': 0.149, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599988</th>\n",
              "      <td>1</td>\n",
              "      <td>everitt ha good job thats right  we gotta thro...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.6486</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.762, 'pos': 0.238, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599989</th>\n",
              "      <td>1</td>\n",
              "      <td>hiphop im glad ur doing well</td>\n",
              "      <td>pos</td>\n",
              "      <td>pos</td>\n",
              "      <td>0.6249</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.44, 'pos': 0.56, 'compou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599990</th>\n",
              "      <td>1</td>\n",
              "      <td>wooooo xbox is back</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599991</th>\n",
              "      <td>1</td>\n",
              "      <td>mmmm  that sounds absolutely perfect but my ...</td>\n",
              "      <td>neg</td>\n",
              "      <td>neu</td>\n",
              "      <td>-0.2967</td>\n",
              "      <td>{'neg': 0.153, 'neu': 0.744, 'pos': 0.103, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599992</th>\n",
              "      <td>1</td>\n",
              "      <td>recovering from the long weekend</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599993</th>\n",
              "      <td>1</td>\n",
              "      <td>gritboys</td>\n",
              "      <td>neu</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599994</th>\n",
              "      <td>1</td>\n",
              "      <td>forster yeah that does work better than just w...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.7906</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.724, 'pos': 0.276, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>1</td>\n",
              "      <td>just woke up having no school is the best feel...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.5423</td>\n",
              "      <td>{'neg': 0.138, 'neu': 0.503, 'pos': 0.358, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>1</td>\n",
              "      <td>very cool to hear old walt interviews  â</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.3804</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.698, 'pos': 0.302, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>1</td>\n",
              "      <td>are you ready for your mojo makeover ask me fo...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.3612</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.8, 'pos': 0.2, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>1</td>\n",
              "      <td>happy th birthday to my boo of alll time tupac...</td>\n",
              "      <td>pos</td>\n",
              "      <td>neu</td>\n",
              "      <td>0.5719</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.748, 'pos': 0.252, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599999</th>\n",
              "      <td>1</td>\n",
              "      <td>happy charitytuesday</td>\n",
              "      <td>pos</td>\n",
              "      <td>pos</td>\n",
              "      <td>0.5719</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.213, 'pos': 0.787, 'comp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         polarity  ...                                                SIA\n",
              "1599960         1  ...  {'neg': 0.0, 'neu': 0.543, 'pos': 0.457, 'comp...\n",
              "1599961         1  ...  {'neg': 0.0, 'neu': 0.781, 'pos': 0.219, 'comp...\n",
              "1599962         1  ...  {'neg': 0.361, 'neu': 0.412, 'pos': 0.227, 'co...\n",
              "1599963         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599964         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599965         1  ...  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...\n",
              "1599966         1  ...  {'neg': 0.083, 'neu': 0.789, 'pos': 0.128, 'co...\n",
              "1599967         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599968         1  ...  {'neg': 0.0, 'neu': 0.527, 'pos': 0.473, 'comp...\n",
              "1599969         1  ...  {'neg': 0.0, 'neu': 0.86, 'pos': 0.14, 'compou...\n",
              "1599970         1  ...  {'neg': 0.0, 'neu': 0.58, 'pos': 0.42, 'compou...\n",
              "1599971         1  ...  {'neg': 0.0, 'neu': 0.849, 'pos': 0.151, 'comp...\n",
              "1599972         1  ...  {'neg': 0.0, 'neu': 0.541, 'pos': 0.459, 'comp...\n",
              "1599973         1  ...  {'neg': 0.39, 'neu': 0.61, 'pos': 0.0, 'compou...\n",
              "1599974         1  ...  {'neg': 0.242, 'neu': 0.758, 'pos': 0.0, 'comp...\n",
              "1599975         1  ...  {'neg': 0.0, 'neu': 0.705, 'pos': 0.295, 'comp...\n",
              "1599976         1  ...  {'neg': 0.0, 'neu': 0.593, 'pos': 0.407, 'comp...\n",
              "1599977         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599978         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599979         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599980         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599981         1  ...  {'neg': 0.0, 'neu': 0.469, 'pos': 0.531, 'comp...\n",
              "1599982         1  ...  {'neg': 0.128, 'neu': 0.775, 'pos': 0.097, 'co...\n",
              "1599983         1  ...  {'neg': 0.0, 'neu': 0.878, 'pos': 0.122, 'comp...\n",
              "1599984         1  ...  {'neg': 0.0, 'neu': 0.788, 'pos': 0.212, 'comp...\n",
              "1599985         1  ...  {'neg': 0.091, 'neu': 0.909, 'pos': 0.0, 'comp...\n",
              "1599986         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599987         1  ...  {'neg': 0.0, 'neu': 0.851, 'pos': 0.149, 'comp...\n",
              "1599988         1  ...  {'neg': 0.0, 'neu': 0.762, 'pos': 0.238, 'comp...\n",
              "1599989         1  ...  {'neg': 0.0, 'neu': 0.44, 'pos': 0.56, 'compou...\n",
              "1599990         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599991         1  ...  {'neg': 0.153, 'neu': 0.744, 'pos': 0.103, 'co...\n",
              "1599992         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599993         1  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "1599994         1  ...  {'neg': 0.0, 'neu': 0.724, 'pos': 0.276, 'comp...\n",
              "1599995         1  ...  {'neg': 0.138, 'neu': 0.503, 'pos': 0.358, 'co...\n",
              "1599996         1  ...  {'neg': 0.0, 'neu': 0.698, 'pos': 0.302, 'comp...\n",
              "1599997         1  ...  {'neg': 0.0, 'neu': 0.8, 'pos': 0.2, 'compound...\n",
              "1599998         1  ...  {'neg': 0.0, 'neu': 0.748, 'pos': 0.252, 'comp...\n",
              "1599999         1  ...  {'neg': 0.0, 'neu': 0.213, 'pos': 0.787, 'comp...\n",
              "\n",
              "[40 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}